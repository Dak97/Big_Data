{"class":"org.apache.spark.ml.feature.Tokenizer","timestamp":1696068133264,"sparkVersion":"3.4.1","uid":"Tokenizer_18a773e93e97","paramMap":{"outputCol":"words","inputCol":"text"},"defaultParamMap":{"outputCol":"Tokenizer_18a773e93e97__output"}}
